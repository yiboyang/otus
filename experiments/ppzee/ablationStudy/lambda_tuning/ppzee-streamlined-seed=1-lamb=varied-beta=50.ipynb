{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTUS | $p p > Z > e^+ e^-$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the streamlined training procedure in experiments/ppzee/alternateSeedTests/ppzee-streamlined-seed=1.ipynb\n",
    "# at 7e31a97, but with various settings of latent space loss weight ('lamb') in order to test out its effect on the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks applies OTUS to our first test case: $Z$ boson decaying into an electron ($e^-$) positron ($e^+$).\n",
    "\n",
    "Our physical latent-space is the $e^+$, $e^-$ 4-momentum information produced by the program MadGraph and our data-space data is the $e^+$, $e^-$ 4-momentum information produced by the program Delphes.\n",
    "\n",
    "We arrange this information into 8 dimensional vectors\n",
    "- Latent space (z): [$p^{\\mu}_{e^-}$,$p^{\\mu}_{e^+}$]\n",
    "- Data space (x):   [$p^{\\mu}_{e^-}$,$p^{\\mu}_{e^+}$]\n",
    "\n",
    "where $p^{\\mu}=[p_x, p_y, p_z, E]$ is the 4-momentum of the given particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional Losses and Constraints:\n",
    "We impose the following additional losses and constraints in this problem.\n",
    "\n",
    "First, we impose a constraint on the learned mappings via \"anchor losses\". This constrains the direction of the electron's 3-momenta when transforming from x-space to z-space and vice versa.\n",
    "\n",
    "Second, we explicitly enforce the Minkowski metric in the output of the networks. Namely, the networks predict the 3-momenta ($\\vec{p}$) of the particles. Energy information is then restored using the Minkowski metric: $E^2 = |\\vec{p}|^2 + m^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the paper for more details: https://arxiv.org/abs/2101.08944."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "root_dir = '../../../'\n",
    "\n",
    "#-- Add utilityFunctions/ to easily use utility .py files --#\n",
    "import sys\n",
    "sys.path.append(os.path.join(root_dir, \"utilityFunctions/\"))\n",
    "\n",
    "#-- Determine if using GPU or CPU --#\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'  # Set to '-1' to disable GPU\n",
    "from configs import device, data_dims\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data type:  float32\n"
     ]
    }
   ],
   "source": [
    "data_directory    = os.path.join(root_dir, \"data/\")\n",
    "dataset_name      = 'ppzee'\n",
    "\n",
    "#-- Set random seeds --#\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#-- Set data type --#\n",
    "from configs import float_type\n",
    "print('Using data type: ', float_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data total shapes:  (331699, 8) (331699, 8)\n",
      "z_train shape, x_train shape:  (291699, 8) (291699, 8)\n",
      "z_val   shape, x_val   shape:  (40000, 8) (40000, 8)\n"
     ]
    }
   ],
   "source": [
    "from func_utils import get_dataset, standardize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#-- Get training and validation dataset --#\n",
    "dataset = get_dataset(dataset_name, data_dir=data_directory) \n",
    "z_data, x_data = dataset['z_data'], dataset['x_data']\n",
    "\n",
    "MET = False # Exclude Missing Transverse Energy (MET) from x-space data\n",
    "if MET == False:\n",
    "    x_data = x_data[:, :-4]\n",
    "print(\"Data total shapes: \",z_data.shape, x_data.shape)\n",
    "\n",
    "x_dim = int(x_data.shape[1])\n",
    "z_dim = int(z_data.shape[1])\n",
    "\n",
    "#-- Split into training and validation sets --#\n",
    "train_size = 291699\n",
    "val_size = 40000  # Validation set used to evaluate/tune models\n",
    "\n",
    "x_train = x_data[:train_size, :]\n",
    "x_val = x_data[train_size:train_size+val_size, :]\n",
    "\n",
    "z_train = z_data[:train_size, :]\n",
    "z_val = z_data[train_size:train_size+val_size, :]\n",
    "\n",
    "#-- Convert data to proper type --#\n",
    "x_train, x_val, z_train, z_val = list(map(lambda x: x.astype(float_type), [x_train, x_val, z_train, z_val]))\n",
    "\n",
    "#-- Obtain mean and std information --#\n",
    "# This is needed to standardize/unstandardize data\n",
    "x_train_mean, x_train_std = np.mean(x_train, axis=0), np.std(x_train, axis=0) \n",
    "z_train_mean, z_train_std = np.mean(z_train, axis=0), np.std(z_train, axis=0)\n",
    "\n",
    "#-- Set evaluation parameters --#\n",
    "eval_batch_size = 20000  # Always use high batch size on validation set to accurately assess performance\n",
    "eval_loaders = DataLoader(dataset=x_val, batch_size=eval_batch_size, shuffle=True), \\\n",
    "               DataLoader(dataset=z_val, batch_size=eval_batch_size, shuffle=True)\n",
    "\n",
    "print(\"z_train shape, x_train shape: \", z_train.shape, x_train.shape)\n",
    "print(\"z_val   shape, x_val   shape: \", z_val.shape, x_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target invariant masses (for both training and validation data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invariant mass relation: $m^2 = E^2 - |\\vec{p}|^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X space\n",
      "particle 0 mass^2 = 2.01129e-15 +- 3.62862e-12\n",
      "particle 1 mass^2 = -1.17544e-14 +- 3.50494e-12\n",
      "Z space\n",
      "particle 0 mass^2 = -1.34586e-09 +- 6.17582e-07\n",
      "particle 1 mass^2 = -1.48398e-10 +- 5.71702e-07\n"
     ]
    }
   ],
   "source": [
    "#-- Look at m2 values empirically --#\n",
    "print('X space')\n",
    "tmp = x_data\n",
    "for i in range(int(tmp.shape[1] / 4)):\n",
    "    p = tmp[:, 4*i : 4*i+3]  # 3-momentum, (px, py, pz)\n",
    "    E = tmp[:, 4*i+3]        # Energy\n",
    "    m2 = (E**2 - (p ** 2).sum(axis=-1))\n",
    "    print('particle %d mass^2 = %g +- %g' %(i, m2.mean(), m2.std()))\n",
    "\n",
    "print('Z space')\n",
    "tmp = z_data\n",
    "for i in range(int(tmp.shape[1] / 4)):\n",
    "    p = tmp[:, 4*i : 4*i+3]  # 3-momentum, (px, py, pz)\n",
    "    E = tmp[:, 4*i+3]        # Energy\n",
    "    m2 = (E**2 - (p ** 2).sum(axis=-1))\n",
    "    print('particle %d mass^2 = %g +- %g' %(i, m2.mean(), m2.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the fact that these values are slightly negative is a purely numerical effect. Thus we instead define them to the value they should have, namely 0. (massless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Define target invariant masses --#\n",
    "x_inv_masses = np.zeros(2)\n",
    "z_inv_masses = np.zeros(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Specific Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from ppzee_utils import train_and_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Meta Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_noise = True  # Whether to use conditional Gaussian (instead of standard normal) for noise in enc/dec\n",
    "if cond_noise:\n",
    "    from models import CondNoiseAutoencoder\n",
    "    Autoencoder = CondNoiseAutoencoder  # Define alias \n",
    "else:\n",
    "    from models import Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Latent loss function: \n",
    "Finite sample approximation of Sliced Wasserstein Distance (SWD) between $p(z)$ and $p_E(z) = \\int_x p(x) p_E(z|x)$\n",
    "- $L_{latent}(Z, \\tilde{Z}) = \\frac{1}{L * M} \\sum_{l=1}^{L} \\sum_{m=1}^{M} c((\\theta_l \\cdot z_m)_{sorted}, (\\theta_l \\cdot \\tilde{z}_m)_{sorted})$ \n",
    "\n",
    "where $c(\\cdot, \\cdot) = |\\cdot - \\cdot|^2$\n",
    "\n",
    "###### Data loss function: \n",
    "- $L_{data}(X, \\tilde{X}) = \\frac{1}{M} \\sum_{m=1}^M c(x_m,  \\tilde{x}_m)$\n",
    "\n",
    "where $c(\\cdot, \\cdot) = |\\cdot - \\cdot|^2$\n",
    "\n",
    "###### Additional loss functions: \n",
    "Encoder and decoder anchor losses\n",
    "- $L_{A}(X, \\tilde{Z}) = \\frac{1}{M} \\sum_{m=1}^M c_A(x_m, \\tilde{z}_m)$\n",
    "- $L_{A}(Z, \\tilde{X}') = \\frac{1}{M} \\sum_{m=1}^M c_A(z_m, \\tilde{x}'_m)$\n",
    "\n",
    "see the paper for additional details about $c_A$.\n",
    "\n",
    "###### Full loss function:\n",
    "- $L_{tot} = \\beta L_{data}(X, \\tilde{X}) + \\lambda L_{latent}(Z, \\tilde{Z}) + \\nu_e L_{A}(X, \\tilde{Z}) + \\nu_d L_{A}(Z, \\tilde{X}')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core Hyperparameters\n",
    "The hyperparameter definitions are as follows:\n",
    "- num_hidden_layers:    The number of hidden layers in both the encoder and decoder networks\n",
    "- dim_per_hidden_layer: The dimensions per hidden layer in both the encoder and decoder networks\n",
    "- lr: The learning rate of the networks\n",
    "- lamb: The $\\lambda$ coefficient in front of the latent loss term\n",
    "- num_slices: Number of random projections used for computing SWD\n",
    "- epochs: The number of epochs used during training\n",
    "\n",
    "Hyperparameters for other losses that were tried, but use during main training is currently discouraged:\n",
    "- tau: Coefficient in front of the alternate data-space loss (\"alt_x_loss\"), which is the SWD between $p(x)$ and $p_D(x):=\\int_z p(z) p_D(x|z)$\n",
    "- rho: Coefficient in front of an additional decoder constraint loss (based on soft-penalty approach to learning hard thresholds/ttbar_constraints)\n",
    "\n",
    "###### Joint Training Hyperparameters\n",
    "\n",
    "- beta: Coefficient in front of data loss, $L_{data}$     \n",
    "- nu_e: Coefficient in front of the encoder \"anchor loss\" \n",
    "- nu_d: Coefficient in front of the decoder \"anchor loss\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_hidden_layers': 1,\n",
    "    'dim_per_hidden_layer': 128,\n",
    "    'lr': 0.001,\n",
    "    'beta': 1.,  # weight of the data reconstruction loss\n",
    "    'lamb': 1.,  # weight of the latent space matching loss\n",
    "    'tau': 0,  \n",
    "    'rho': 0,  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "num_hidden_layers, dim_per_hidden_layer = config['num_hidden_layers'], config['dim_per_hidden_layer']\n",
    "hidden_layer_dims = num_hidden_layers * [dim_per_hidden_layer]\n",
    "\n",
    "activation = torch.nn.ReLU\n",
    "sigma_fun = 'softplus'  # Default is 'exp'\n",
    "model = Autoencoder(x_dim=x_dim, z_dim=z_dim, hidden_layer_dims=hidden_layer_dims, raw_io=True,\n",
    "                    x_stats=np.stack([x_train_mean, x_train_std]), z_stats=np.stack([z_train_mean, z_train_std]),\n",
    "                    x_inv_masses=x_inv_masses, z_inv_masses=z_inv_masses,\n",
    "                    stoch_enc=True, stoch_dec=True, activation=activation, sigma_fun=sigma_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CondNoiseAutoencoder(\n",
       "  (encoder): CondNoiseMLP(\n",
       "    (sigma_fun): Softplus(beta=1, threshold=20)\n",
       "    (output_nn): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "    (cond_noise_nn): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): CondNoiseMLP(\n",
       "    (sigma_fun): Softplus(beta=1, threshold=20)\n",
       "    (output_nn): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "    (cond_noise_nn): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 20000\n",
    "train_loaders = DataLoader(dataset=x_train, batch_size=train_batch_size, shuffle=True), \\\n",
    "                DataLoader(dataset=z_train, batch_size=train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through different hyperparameters and train/eval a model for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with lamb=0.001\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 0.001, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:2854.11, x_loss:2751.86, z_loss:1675.67, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.01137\n",
      "eval -- loss:3124.13, x_loss:2706.13, z_loss:1616.07, alt_x_loss:1508.06, anchor_loss:2.44527\n",
      "epoch:\t100\n",
      "train -- loss:2.71684, x_loss:1.08185, z_loss:603.848, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.020623\n",
      "eval -- loss:3865.83, x_loss:1.08672, z_loss:611.195, alt_x_loss:3254.64, anchor_loss:0.0342674\n",
      "epoch:\t200\n",
      "train -- loss:1.31843, x_loss:0.652602, z_loss:312.747, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00706171\n",
      "eval -- loss:2220.17, x_loss:0.558024, z_loss:304.893, alt_x_loss:1915.28, anchor_loss:0.0126758\n",
      "epoch:\t300\n",
      "train -- loss:0.662566, x_loss:0.293182, z_loss:190.331, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00358105\n",
      "eval -- loss:1147.15, x_loss:0.302392, z_loss:191.683, alt_x_loss:955.466, anchor_loss:0.0065472\n",
      "epoch:\t399\n",
      "train -- loss:0.388089, x_loss:0.186488, z_loss:124.709, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00153786\n",
      "eval -- loss:684.714, x_loss:0.184086, z_loss:125.717, alt_x_loss:558.997, anchor_loss:0.00285939\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 0.001, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:0.309538, x_loss:0.184358, z_loss:125.18, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:675.608, x_loss:0.18173, z_loss:121.771, alt_x_loss:553.837, anchor_loss:0.00289078\n",
      "epoch:\t100\n",
      "train -- loss:0.4124, x_loss:0.328201, z_loss:84.1992, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:412.108, x_loss:0.365651, z_loss:75.777, alt_x_loss:336.331, anchor_loss:0.0145835\n",
      "epoch:\t200\n",
      "train -- loss:0.16109, x_loss:0.100539, z_loss:60.5503, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:291.765, x_loss:0.093906, z_loss:58.0174, alt_x_loss:233.748, anchor_loss:0.0305762\n",
      "epoch:\t300\n",
      "train -- loss:0.779097, x_loss:0.728702, z_loss:50.3945, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:240.424, x_loss:0.399578, z_loss:50.1594, alt_x_loss:190.264, anchor_loss:0.0484859\n",
      "epoch:\t400\n",
      "train -- loss:0.144758, x_loss:0.0986273, z_loss:46.1308, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:203.698, x_loss:0.0866919, z_loss:43.4278, alt_x_loss:160.27, anchor_loss:0.0692448\n",
      "epoch:\t500\n",
      "train -- loss:0.104978, x_loss:0.0516274, z_loss:53.3507, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:179.913, x_loss:0.0553923, z_loss:38.1216, alt_x_loss:141.791, anchor_loss:0.0926635\n",
      "epoch:\t600\n",
      "train -- loss:0.395861, x_loss:0.356552, z_loss:39.309, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:163.78, x_loss:0.336397, z_loss:36.4049, alt_x_loss:127.375, anchor_loss:0.117249\n",
      "epoch:\t700\n",
      "train -- loss:0.129146, x_loss:0.0907751, z_loss:38.3712, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:145.227, x_loss:0.0931332, z_loss:32.0033, alt_x_loss:113.224, anchor_loss:0.140299\n",
      "epoch:\t799\n",
      "train -- loss:0.0611583, x_loss:0.0263829, z_loss:34.7754, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:134.902, x_loss:0.0290144, z_loss:28.8507, alt_x_loss:106.051, anchor_loss:0.161209\n",
      "Saved model weights to ./swae-lamb=0.001.pkl\n",
      "\n",
      "\n",
      "Training with lamb=0.01\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 0.01, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:2873.54, x_loss:2758.15, z_loss:1557.64, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.99618\n",
      "eval -- loss:3008.08, x_loss:2715, z_loss:1492.51, alt_x_loss:1515.57, anchor_loss:2.3649\n",
      "epoch:\t100\n",
      "train -- loss:2.24791, x_loss:0.939424, z_loss:75.9916, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.0109713\n",
      "eval -- loss:263.496, x_loss:0.95822, z_loss:66.6672, alt_x_loss:196.829, anchor_loss:0.0193407\n",
      "epoch:\t200\n",
      "train -- loss:1.18353, x_loss:0.37509, z_loss:55.0674, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00515526\n",
      "eval -- loss:183.844, x_loss:0.385502, z_loss:46.5205, alt_x_loss:137.324, anchor_loss:0.00966585\n",
      "epoch:\t300\n",
      "train -- loss:0.770044, x_loss:0.244776, z_loss:38.5366, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00279804\n",
      "eval -- loss:128.229, x_loss:0.240788, z_loss:36.9253, alt_x_loss:91.3034, anchor_loss:0.0052334\n",
      "epoch:\t399\n",
      "train -- loss:0.458836, x_loss:0.170658, z_loss:22.4677, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00127003\n",
      "eval -- loss:89.9943, x_loss:0.171878, z_loss:21.7283, alt_x_loss:68.2659, anchor_loss:0.00243935\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 0.01, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:0.498359, x_loss:0.213576, z_loss:28.4783, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:89.6662, x_loss:0.20876, z_loss:21.1289, alt_x_loss:68.5373, anchor_loss:0.00256013\n",
      "epoch:\t100\n",
      "train -- loss:0.260549, x_loss:0.116551, z_loss:14.3998, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:61.9679, x_loss:0.118133, z_loss:11.3417, alt_x_loss:50.6262, anchor_loss:0.0360779\n",
      "epoch:\t200\n",
      "train -- loss:0.212542, x_loss:0.108178, z_loss:10.4364, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:48.286, x_loss:0.100689, z_loss:8.77997, alt_x_loss:39.506, anchor_loss:0.0590969\n",
      "epoch:\t300\n",
      "train -- loss:0.319924, x_loss:0.234112, z_loss:8.58118, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:36.6174, x_loss:0.196697, z_loss:7.06719, alt_x_loss:29.5502, anchor_loss:0.0733049\n",
      "epoch:\t400\n",
      "train -- loss:0.283851, x_loss:0.188885, z_loss:9.49661, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:30.817, x_loss:0.147831, z_loss:6.34884, alt_x_loss:24.4681, anchor_loss:0.0845801\n",
      "epoch:\t500\n",
      "train -- loss:0.266873, x_loss:0.0728209, z_loss:19.4052, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:22.5997, x_loss:0.0791669, z_loss:4.51861, alt_x_loss:18.0811, anchor_loss:0.0949123\n",
      "epoch:\t600\n",
      "train -- loss:0.109819, x_loss:0.0341766, z_loss:7.56423, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:19.7374, x_loss:0.035544, z_loss:4.5493, alt_x_loss:15.1881, anchor_loss:0.104381\n",
      "epoch:\t700\n",
      "train -- loss:0.158165, x_loss:0.0690509, z_loss:8.91138, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:15.0727, x_loss:0.0931616, z_loss:3.61097, alt_x_loss:11.4617, anchor_loss:0.113636\n",
      "epoch:\t799\n",
      "train -- loss:0.120981, x_loss:0.028235, z_loss:9.27465, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:14.1598, x_loss:0.0278377, z_loss:3.92585, alt_x_loss:10.2339, anchor_loss:0.120543\n",
      "Saved model weights to ./swae-lamb=0.01.pkl\n",
      "\n",
      "\n",
      "Training with lamb=0.1\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 0.1, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:2985.89, x_loss:2792.51, z_loss:947.073, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.97349\n",
      "eval -- loss:2412.25, x_loss:2760.06, z_loss:867.638, alt_x_loss:1544.61, anchor_loss:1.99903\n",
      "epoch:\t100\n",
      "train -- loss:4.204, x_loss:1.38357, z_loss:20.8499, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.0147088\n",
      "eval -- loss:55.7223, x_loss:1.15256, z_loss:11.2193, alt_x_loss:44.503, anchor_loss:0.026631\n",
      "epoch:\t200\n",
      "train -- loss:1.36127, x_loss:0.476341, z_loss:5.75275, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00619317\n",
      "eval -- loss:37.6657, x_loss:0.493957, z_loss:3.87622, alt_x_loss:33.7895, anchor_loss:0.0116131\n",
      "epoch:\t300\n",
      "train -- loss:1.24963, x_loss:0.346311, z_loss:7.27039, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.0035255\n",
      "eval -- loss:19.6875, x_loss:0.296322, z_loss:2.67822, alt_x_loss:17.0093, anchor_loss:0.00663922\n",
      "epoch:\t399\n",
      "train -- loss:0.657558, x_loss:0.273555, z_loss:2.91704, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.001846\n",
      "eval -- loss:9.32026, x_loss:0.368052, z_loss:1.3445, alt_x_loss:7.97576, anchor_loss:0.00364134\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 0.1, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:\t0\n",
      "train -- loss:1.21472, x_loss:0.252764, z_loss:9.61959, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:8.82647, x_loss:0.312872, z_loss:1.23216, alt_x_loss:7.59432, anchor_loss:0.00369009\n",
      "epoch:\t100\n",
      "train -- loss:0.966794, x_loss:0.255351, z_loss:7.11442, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.27039, x_loss:0.246694, z_loss:1.38712, alt_x_loss:3.88327, anchor_loss:0.0077922\n",
      "epoch:\t200\n",
      "train -- loss:0.402948, x_loss:0.123675, z_loss:2.79273, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.54483, x_loss:0.156895, z_loss:1.62872, alt_x_loss:2.91611, anchor_loss:0.0088184\n",
      "epoch:\t300\n",
      "train -- loss:0.509863, x_loss:0.177103, z_loss:3.3276, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.10491, x_loss:0.151749, z_loss:1.51625, alt_x_loss:2.58867, anchor_loss:0.00942441\n",
      "epoch:\t400\n",
      "train -- loss:0.668099, x_loss:0.113786, z_loss:5.54313, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.05965, x_loss:0.115528, z_loss:1.63586, alt_x_loss:2.4238, anchor_loss:0.00964287\n",
      "epoch:\t500\n",
      "train -- loss:1.88733, x_loss:0.218173, z_loss:16.6916, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2.4853, x_loss:0.123937, z_loss:1.06586, alt_x_loss:1.41945, anchor_loss:0.00987728\n",
      "epoch:\t600\n",
      "train -- loss:0.609109, x_loss:0.234778, z_loss:3.74331, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.20217, x_loss:0.141685, z_loss:1.44966, alt_x_loss:1.7525, anchor_loss:0.010019\n",
      "epoch:\t700\n",
      "train -- loss:0.716915, x_loss:0.0732896, z_loss:6.43625, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2.46789, x_loss:0.091514, z_loss:1.05564, alt_x_loss:1.41226, anchor_loss:0.0103021\n",
      "epoch:\t799\n",
      "train -- loss:0.970447, x_loss:0.218976, z_loss:7.51471, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.89512, x_loss:0.181244, z_loss:1.71382, alt_x_loss:2.1813, anchor_loss:0.0105077\n",
      "Saved model weights to ./swae-lamb=0.1.pkl\n",
      "\n",
      "\n",
      "Training with lamb=1\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:3830.17, x_loss:2943.64, z_loss:786.829, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.99395\n",
      "eval -- loss:2390.63, x_loss:2930.31, z_loss:711.992, alt_x_loss:1678.64, anchor_loss:1.9234\n",
      "epoch:\t100\n",
      "train -- loss:41.4457, x_loss:11.9029, z_loss:20.9698, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.171459\n",
      "eval -- loss:97.4924, x_loss:10.2757, z_loss:6.71555, alt_x_loss:90.7769, anchor_loss:0.327617\n",
      "epoch:\t200\n",
      "train -- loss:6.92196, x_loss:2.13721, z_loss:3.8017, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.019661\n",
      "eval -- loss:12.134, x_loss:2.29333, z_loss:1.71357, alt_x_loss:10.4205, anchor_loss:0.0373688\n",
      "epoch:\t300\n",
      "train -- loss:9.43353, x_loss:2.29432, z_loss:6.66549, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00947432\n",
      "eval -- loss:5.3053, x_loss:1.40895, z_loss:1.8481, alt_x_loss:3.45721, anchor_loss:0.0179548\n",
      "epoch:\t399\n",
      "train -- loss:3.49792, x_loss:0.741095, z_loss:2.4479, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00617849\n",
      "eval -- loss:4.17967, x_loss:0.785676, z_loss:1.48228, alt_x_loss:2.69739, anchor_loss:0.0121825\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:10.5641, x_loss:1.14898, z_loss:9.41511, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.5643, x_loss:0.942965, z_loss:1.23934, alt_x_loss:2.32496, anchor_loss:0.0126587\n",
      "epoch:\t100\n",
      "train -- loss:8.38131, x_loss:1.923, z_loss:6.4583, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.25219, x_loss:1.04912, z_loss:1.17782, alt_x_loss:2.07436, anchor_loss:0.0154588\n",
      "epoch:\t200\n",
      "train -- loss:3.20345, x_loss:0.521352, z_loss:2.6821, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.55691, x_loss:0.980435, z_loss:1.54184, alt_x_loss:2.01507, anchor_loss:0.0174515\n",
      "epoch:\t300\n",
      "train -- loss:3.98575, x_loss:0.622083, z_loss:3.36367, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.2736, x_loss:0.538984, z_loss:1.36625, alt_x_loss:1.90734, anchor_loss:0.0179142\n",
      "epoch:\t400\n",
      "train -- loss:8.19744, x_loss:0.735627, z_loss:7.46182, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.1526, x_loss:0.737309, z_loss:1.74375, alt_x_loss:2.40884, anchor_loss:0.0181433\n",
      "epoch:\t500\n",
      "train -- loss:16.821, x_loss:0.55331, z_loss:16.2676, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2.33375, x_loss:0.463243, z_loss:1.00493, alt_x_loss:1.32882, anchor_loss:0.018025\n",
      "epoch:\t600\n",
      "train -- loss:4.03997, x_loss:0.540177, z_loss:3.49979, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.17796, x_loss:0.673573, z_loss:1.54854, alt_x_loss:1.62941, anchor_loss:0.0176493\n",
      "epoch:\t700\n",
      "train -- loss:6.75477, x_loss:0.841268, z_loss:5.9135, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2.78421, x_loss:1.18159, z_loss:0.962665, alt_x_loss:1.82154, anchor_loss:0.0175322\n",
      "epoch:\t799\n",
      "train -- loss:7.39643, x_loss:0.407033, z_loss:6.9894, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.97434, x_loss:0.484551, z_loss:2.2846, alt_x_loss:2.68974, anchor_loss:0.0172018\n",
      "Saved model weights to ./swae-lamb=1.pkl\n",
      "\n",
      "\n",
      "Training with lamb=10\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 10, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:11086.7, x_loss:3045.87, z_loss:794.071, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.00141\n",
      "eval -- loss:2442.85, x_loss:3042.77, z_loss:722.22, alt_x_loss:1720.63, anchor_loss:1.98016\n",
      "epoch:\t100\n",
      "train -- loss:242.541, x_loss:22.7253, z_loss:14.787, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.43892\n",
      "eval -- loss:124.473, x_loss:22.5792, z_loss:4.10129, alt_x_loss:120.372, anchor_loss:1.74074\n",
      "epoch:\t200\n",
      "train -- loss:115.41, x_loss:21.0064, z_loss:4.46543, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.994988\n",
      "eval -- loss:251.065, x_loss:20.693, z_loss:4.80303, alt_x_loss:246.262, anchor_loss:1.57649\n",
      "epoch:\t300\n",
      "train -- loss:156.659, x_loss:19.33, z_loss:9.64505, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.817565\n",
      "eval -- loss:240.026, x_loss:19.2682, z_loss:3.50397, alt_x_loss:236.522, anchor_loss:1.42677\n",
      "epoch:\t399\n",
      "train -- loss:112.557, x_loss:18.4313, z_loss:5.72952, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.736617\n",
      "eval -- loss:271.105, x_loss:18.6418, z_loss:5.90008, alt_x_loss:265.205, anchor_loss:1.31858\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 10, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:109.617, x_loss:18.7957, z_loss:9.08212, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:280.677, x_loss:18.345, z_loss:3.48268, alt_x_loss:277.195, anchor_loss:1.3248\n",
      "epoch:\t100\n",
      "train -- loss:54.8342, x_loss:13.926, z_loss:4.09082, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:80.7845, x_loss:13.2551, z_loss:2.58863, alt_x_loss:78.1959, anchor_loss:1.58843\n",
      "epoch:\t200\n",
      "train -- loss:37.26, x_loss:11.3284, z_loss:2.59316, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:49.7945, x_loss:11.4148, z_loss:2.30788, alt_x_loss:47.4866, anchor_loss:1.71936\n",
      "epoch:\t300\n",
      "train -- loss:48.1102, x_loss:10.5387, z_loss:3.75715, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:33.4848, x_loss:10.5227, z_loss:2.46934, alt_x_loss:31.0155, anchor_loss:1.82789\n",
      "epoch:\t400\n",
      "train -- loss:72.1751, x_loss:8.75532, z_loss:6.34197, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:28.2767, x_loss:8.45433, z_loss:3.03762, alt_x_loss:25.2391, anchor_loss:1.90125\n",
      "epoch:\t500\n",
      "train -- loss:177.373, x_loss:4.88197, z_loss:17.2491, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:20.5623, x_loss:5.26787, z_loss:2.79885, alt_x_loss:17.7634, anchor_loss:2.00929\n",
      "epoch:\t600\n",
      "train -- loss:44.1357, x_loss:4.72016, z_loss:3.94155, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:16.6192, x_loss:4.49034, z_loss:3.80027, alt_x_loss:12.8189, anchor_loss:2.05978\n",
      "epoch:\t700\n",
      "train -- loss:49.6176, x_loss:3.5697, z_loss:4.60479, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval -- loss:14.5122, x_loss:3.42368, z_loss:2.52268, alt_x_loss:11.9895, anchor_loss:2.10021\n",
      "epoch:\t799\n",
      "train -- loss:94.4832, x_loss:2.61715, z_loss:9.1866, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:14.4175, x_loss:3.26701, z_loss:2.85673, alt_x_loss:11.5608, anchor_loss:2.14813\n",
      "Saved model weights to ./swae-lamb=10.pkl\n",
      "\n",
      "\n",
      "Training with lamb=100\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 100, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:82751.1, x_loss:3056.06, z_loss:795.949, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.00184\n",
      "eval -- loss:2447.4, x_loss:3054.13, z_loss:724.38, alt_x_loss:1723.02, anchor_loss:1.98407\n",
      "epoch:\t100\n",
      "train -- loss:1566.51, x_loss:79.93, z_loss:13.9293, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.87304\n",
      "eval -- loss:67.6095, x_loss:81.838, z_loss:4.21304, alt_x_loss:63.3964, anchor_loss:1.96026\n",
      "epoch:\t200\n",
      "train -- loss:592.966, x_loss:39.1218, z_loss:4.68609, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.7047\n",
      "eval -- loss:67.6485, x_loss:39.2244, z_loss:3.44074, alt_x_loss:64.2078, anchor_loss:1.86383\n",
      "epoch:\t300\n",
      "train -- loss:844.44, x_loss:30.955, z_loss:7.38032, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.50907\n",
      "eval -- loss:59.5423, x_loss:30.6878, z_loss:2.08844, alt_x_loss:57.4539, anchor_loss:1.75244\n",
      "epoch:\t399\n",
      "train -- loss:369.18, x_loss:26.7037, z_loss:2.77193, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.30566\n",
      "eval -- loss:130.276, x_loss:27.0128, z_loss:3.75336, alt_x_loss:126.523, anchor_loss:1.67818\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 100, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:851.992, x_loss:26.0167, z_loss:8.25975, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:81.2535, x_loss:26.8796, z_loss:2.95946, alt_x_loss:78.294, anchor_loss:1.68472\n",
      "epoch:\t100\n",
      "train -- loss:482.106, x_loss:23.3034, z_loss:4.58803, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:36.5295, x_loss:22.1623, z_loss:2.22075, alt_x_loss:34.3088, anchor_loss:1.72499\n",
      "epoch:\t200\n",
      "train -- loss:296.787, x_loss:19.3445, z_loss:2.77442, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:35.8567, x_loss:18.85, z_loss:1.88767, alt_x_loss:33.9691, anchor_loss:1.73047\n",
      "epoch:\t300\n",
      "train -- loss:391.516, x_loss:17.2873, z_loss:3.74229, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:35.3552, x_loss:17.9455, z_loss:2.16725, alt_x_loss:33.1879, anchor_loss:1.72958\n",
      "epoch:\t400\n",
      "train -- loss:450.607, x_loss:18.8319, z_loss:4.31775, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:33.3248, x_loss:17.5608, z_loss:2.992, alt_x_loss:30.3328, anchor_loss:1.75625\n",
      "epoch:\t500\n",
      "train -- loss:1676.97, x_loss:15.6102, z_loss:16.6136, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:31.1667, x_loss:16.0721, z_loss:2.89987, alt_x_loss:28.2668, anchor_loss:1.75471\n",
      "epoch:\t600\n",
      "train -- loss:354.509, x_loss:16.7863, z_loss:3.37722, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:27.2445, x_loss:16.4384, z_loss:3.4485, alt_x_loss:23.796, anchor_loss:1.75265\n",
      "epoch:\t700\n",
      "train -- loss:383.877, x_loss:13.7855, z_loss:3.70092, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:30.7354, x_loss:13.5255, z_loss:2.07259, alt_x_loss:28.6628, anchor_loss:1.7483\n",
      "epoch:\t799\n",
      "train -- loss:1022.27, x_loss:12.2825, z_loss:10.0998, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:31.9301, x_loss:12.6898, z_loss:2.76636, alt_x_loss:29.1638, anchor_loss:1.74191\n",
      "Saved model weights to ./swae-lamb=100.pkl\n",
      "\n",
      "\n",
      "Training with lamb=1000\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1000, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:799308, x_loss:3056.96, z_loss:796.151, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.00186\n",
      "eval -- loss:2447.83, x_loss:3055.15, z_loss:724.613, alt_x_loss:1723.22, anchor_loss:1.98436\n",
      "epoch:\t100\n",
      "train -- loss:14590.6, x_loss:249.555, z_loss:14.2342, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.13637\n",
      "eval -- loss:165.96, x_loss:250.822, z_loss:4.82009, alt_x_loss:161.139, anchor_loss:2.25239\n",
      "epoch:\t200\n",
      "train -- loss:4084.44, x_loss:127.974, z_loss:3.845, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.22928\n",
      "eval -- loss:66.0421, x_loss:133.832, z_loss:3.02657, alt_x_loss:63.0155, anchor_loss:2.31644\n",
      "epoch:\t300\n",
      "train -- loss:8473.74, x_loss:84.863, z_loss:8.27686, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.24027\n",
      "eval -- loss:41.2433, x_loss:84.0637, z_loss:2.09968, alt_x_loss:39.1436, anchor_loss:2.34267\n",
      "epoch:\t399\n",
      "train -- loss:2830.06, x_loss:63.9312, z_loss:2.65552, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.21218\n",
      "eval -- loss:47.5432, x_loss:64.028, z_loss:3.11792, alt_x_loss:44.4253, anchor_loss:2.36975\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1000, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:8466.03, x_loss:63.9967, z_loss:8.40203, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:48.7708, x_loss:65.4741, z_loss:2.90945, alt_x_loss:45.8613, anchor_loss:2.40766\n",
      "epoch:\t100\n",
      "train -- loss:3738.06, x_loss:52.2396, z_loss:3.68582, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:29.3908, x_loss:51.5678, z_loss:2.03325, alt_x_loss:27.3576, anchor_loss:2.44005\n",
      "epoch:\t200\n",
      "train -- loss:3079.14, x_loss:46.9592, z_loss:3.03218, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:36.6409, x_loss:45.7252, z_loss:2.15484, alt_x_loss:34.4861, anchor_loss:2.45355\n",
      "epoch:\t300\n",
      "train -- loss:3787.12, x_loss:37.8553, z_loss:3.74926, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:28.853, x_loss:38.8598, z_loss:2.22105, alt_x_loss:26.6319, anchor_loss:2.49036\n",
      "epoch:\t400\n",
      "train -- loss:4841.72, x_loss:41.0994, z_loss:4.80062, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:27.2453, x_loss:38.088, z_loss:3.39386, alt_x_loss:23.8514, anchor_loss:2.49155\n",
      "epoch:\t500\n",
      "train -- loss:17967.3, x_loss:33.0679, z_loss:17.9343, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:20.8492, x_loss:34.5705, z_loss:2.91589, alt_x_loss:17.9333, anchor_loss:2.49485\n",
      "epoch:\t600\n",
      "train -- loss:3414.87, x_loss:32.2302, z_loss:3.38264, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:21.1379, x_loss:33.3267, z_loss:3.854, alt_x_loss:17.2839, anchor_loss:2.5017\n",
      "epoch:\t700\n",
      "train -- loss:4022.49, x_loss:30.7895, z_loss:3.9917, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:24.5985, x_loss:32.0635, z_loss:2.05166, alt_x_loss:22.5469, anchor_loss:2.50762\n",
      "epoch:\t799\n",
      "train -- loss:9068.46, x_loss:25.3097, z_loss:9.04315, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:20.2644, x_loss:26.6002, z_loss:2.83503, alt_x_loss:17.4294, anchor_loss:2.52761\n",
      "Saved model weights to ./swae-lamb=1000.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "save_dir = '.'\n",
    "\n",
    "lambs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(f'Training with lamb={lamb}')\n",
    "    config['lamb'] = lamb\n",
    "\n",
    "    # Reset seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Create a new model and optimizer\n",
    "    model = Autoencoder(x_dim=x_dim, z_dim=z_dim, hidden_layer_dims=hidden_layer_dims, raw_io=True,\n",
    "                    x_stats=np.stack([x_train_mean, x_train_std]), z_stats=np.stack([z_train_mean, z_train_std]),\n",
    "                    x_inv_masses=x_inv_masses, z_inv_masses=z_inv_masses,\n",
    "                    stoch_enc=True, stoch_dec=True, activation=activation, sigma_fun=sigma_fun)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    \n",
    "    #  Stage-1 training with the anchor penalty\n",
    "    config['nu_e'] = config['nu_d'] = 50  # same setting as in ppzee.ipynb\n",
    "    config['epochs'] = 400  # originally 200; increased to 400 to ensure convergence\n",
    "    history = None\n",
    "    eval_losses, history = train_and_val(model, train_loaders, eval_loaders, config, optimizer, verbose=verbose, \n",
    "                                          prev_hist=history, log_freq=100, lr_decay=False)\n",
    "    # Stage-2 training without the anchor penalty\n",
    "    config['nu_e'] = config['nu_d'] = 0\n",
    "    config['epochs'] = 800  # originally 600; increased to 800 to ensure convergence\n",
    "#     history = None\n",
    "    eval_losses, history = train_and_val(model, train_loaders, eval_loaders, config, optimizer, verbose=verbose, \n",
    "                                          prev_hist=history, log_freq=100, lr_decay=False)\n",
    "    # Save history in JSON-lines format\n",
    "    ## convert pytorch float tensors into plain numpy float arrs in history\n",
    "    for key, val in history.items():\n",
    "        if isinstance(val, (list, np.ndarray)) :\n",
    "            if not isinstance(np.sum(val), (int, np.integer)):  # my crude test to see if this is an array of float type\n",
    "                history[key] = [float(n) for n in val]\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(history)\n",
    "    df.to_json(f'history-lamb={lamb}.jsonl', orient='records', lines=True)\n",
    "    \n",
    "\n",
    "    # Save trained model\n",
    "    save_path = os.path.join(save_dir, f'swae-lamb={lamb}.pkl')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print('Saved model weights to', save_path)\n",
    "\n",
    "    # Reset seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Collect model results\n",
    "    model.to('cpu')\n",
    "    model.encoder.output_stats.to('cpu')\n",
    "    model.decoder.output_stats.to('cpu')\n",
    "\n",
    "    all_arrs = {'train': {}, 'val': {}}  # This will store all numpy arrays of interest\n",
    "    all_arrs['train']['x'] = x_train\n",
    "    all_arrs['train']['z'] = z_train\n",
    "    all_arrs['val']['x']   = x_val\n",
    "    all_arrs['val']['z']   = z_val\n",
    "\n",
    "    for data_key in 'train', 'val':\n",
    "        arrs = all_arrs[data_key]\n",
    "        arrs['z_decoded']       = model.decode(torch.from_numpy(arrs['z'])) # p_D(x) = \\int_z p(z) p_D(x|z)  \"x_pred_truth\"\n",
    "        arrs['x_encoded']       = model.encode(torch.from_numpy(arrs['x'])) # p_E(z) = \\int_x p(x) p_E(z|x)  \"z_pred\"\n",
    "        arrs['x_reconstructed'] = model.decode(arrs['x_encoded'])     # p_D(y) = \\int_x \\int_z p(x) p_E(z|x) p_D(y|z) \"x_pred\"\n",
    "\n",
    "        # Feed the same z input to the decoder multiple times and study the stochastic of the output\n",
    "        num_repeats = 100\n",
    "        num_diff_zs = 100\n",
    "        arrs['z_rep']         = np.array([np.repeat(arrs['z'][i:i+1], num_repeats, axis=0) for i in range(num_diff_zs)]) # \"z_fixed\"\n",
    "        z_rep_tensor          = torch.from_numpy(arrs['z_rep'])                                                          # tmp\n",
    "        arrs['z_decoded_rep'] = np.array([model.decode(z_rep_tensor[i]).detach().numpy() for i in range(num_diff_zs)])   # \"x_pred_truth_fixed\"\n",
    "        arrs['x_rep']         = np.array([np.repeat(arrs['x'][i:i+1], num_repeats, axis=0) for i in range(num_diff_zs)]) # \"x_fixed\"\n",
    "\n",
    "        # Convert all results to numpy arrays\n",
    "        for (field, arr) in arrs.items():\n",
    "            if isinstance(arr, torch.Tensor):\n",
    "                arrs[field] = arr.detach().numpy()\n",
    "    \n",
    "    from plot_utils import plotFunction\n",
    "    # Z-space\n",
    "    data_key = 'val'\n",
    "    arrs = all_arrs[data_key]\n",
    "    dataList = [arrs['z'], arrs['x_encoded']]\n",
    "    pltDim   = (2,4)\n",
    "    numBins  = 50\n",
    "    binsList = [np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins),\n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins)]\n",
    "    particleNameList = [r'$e^-$', r'$e^+$']\n",
    "\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList = binsList, particleNameList = particleNameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'Z_marginals-lamb={lamb}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # X-space\n",
    "    # Set plotting parameters\n",
    "    dataList = [arrs['x'], arrs['x_reconstructed'], arrs['z_decoded']]\n",
    "    pltDim   = (2,4)\n",
    "    numBins  = 50\n",
    "    binsList = [np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins),\n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins)]\n",
    "    particleNameList = [r'$e^-$', r'$e^+$']\n",
    "\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList = binsList, particleNameList = particleNameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'X_marginals-lamb={lamb}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Derived quantity (Z-boson mass)\n",
    "    from func_utils import Zboson_mass\n",
    "    ## Z-space\n",
    "    dataList = [Zboson_mass(arrs['z']), Zboson_mass(arrs['x_encoded'])]\n",
    "    pltDim   = (1,1)\n",
    "    numBins  = 40\n",
    "    binsList = [np.linspace(70.,110., numBins)]\n",
    "    particleNameList = []\n",
    "    nameList = [r'$M_Z$', r'Counts']\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList=binsList, particleNameList=particleNameList, nameList=nameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'Z_derived-lamb={lamb}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    ## X-space\n",
    "    dataList = [Zboson_mass(arrs['x']), Zboson_mass(arrs['x_reconstructed']), Zboson_mass(arrs['z_decoded'])] \n",
    "    pltDim   = (1,1)\n",
    "    numBins  = 40\n",
    "    binsList = [np.linspace(70.,110., numBins)]\n",
    "    particleNameList = []\n",
    "    nameList = [r'$M_Z$', r'Counts']\n",
    "\n",
    "    # Create plot\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList=binsList, particleNameList=particleNameList, nameList=nameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'X_derived-lamb={lamb}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Transport plots\n",
    "    from plot_utils import fullTransportPlot \n",
    "    nzList    = [20,20,20,20,20,20,20,20]\n",
    "    nxList    = [20,20,20,20,20,20,20,20]\n",
    "    x_display_lims = [(-100, 100), (-100, 100), (-400, 400), (0, 400)]\n",
    "    limzList = x_display_lims * 2\n",
    "    limxList = x_display_lims * 2\n",
    "    pltDim    = (2,4)\n",
    "    titleList = [r'$p_x$',r'$p_y$',r'$p_z$',r'$E$','','','','']\n",
    "    fig = fullTransportPlot(arrs['z'], arrs['z_decoded'][:, 0:8], nzList=nzList, nxList=nxList, limzList=limzList, limxList=limxList, pltDim=pltDim, titleList=titleList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'z-z_decoded-transport-lamb={lamb}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = fullTransportPlot(arrs['x_encoded'], arrs['x_reconstructed'][:, 0:8], nzList=nzList, nxList=nxList, limzList=limzList, limxList=limxList, pltDim=pltDim, titleList=titleList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'x_encoded-x_reconstructed-transport-lamb={lamb}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
