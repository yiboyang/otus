{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTUS | $p p > Z > e^+ e^-$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the streamlined training procedure in experiments/ppzee/alternateSeedTests/ppzee-streamlined-seed=1.ipynb\n",
    "# at 7e31a97, but with various settings of the anchor loss weight ('nu') in the initial training stage (the second\n",
    "# stage of training turns off the anchor loss) while keeping lamb fixed at 1, in order to test out the effect of\n",
    "# the anchor loss weight hyperparameter on the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks applies OTUS to our first test case: $Z$ boson decaying into an electron ($e^-$) positron ($e^+$).\n",
    "\n",
    "Our physical latent-space is the $e^+$, $e^-$ 4-momentum information produced by the program MadGraph and our data-space data is the $e^+$, $e^-$ 4-momentum information produced by the program Delphes.\n",
    "\n",
    "We arrange this information into 8 dimensional vectors\n",
    "- Latent space (z): [$p^{\\mu}_{e^-}$,$p^{\\mu}_{e^+}$]\n",
    "- Data space (x):   [$p^{\\mu}_{e^-}$,$p^{\\mu}_{e^+}$]\n",
    "\n",
    "where $p^{\\mu}=[p_x, p_y, p_z, E]$ is the 4-momentum of the given particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional Losses and Constraints:\n",
    "We impose the following additional losses and constraints in this problem.\n",
    "\n",
    "First, we impose a constraint on the learned mappings via \"anchor losses\". This constrains the direction of the electron's 3-momenta when transforming from x-space to z-space and vice versa.\n",
    "\n",
    "Second, we explicitly enforce the Minkowski metric in the output of the networks. Namely, the networks predict the 3-momenta ($\\vec{p}$) of the particles. Energy information is then restored using the Minkowski metric: $E^2 = |\\vec{p}|^2 + m^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the paper for more details: https://arxiv.org/abs/2101.08944."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "root_dir = '../../../'\n",
    "\n",
    "#-- Add utilityFunctions/ to easily use utility .py files --#\n",
    "import sys\n",
    "sys.path.append(os.path.join(root_dir, \"utilityFunctions/\"))\n",
    "\n",
    "#-- Determine if using GPU or CPU --#\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'  # Set to '-1' to disable GPU\n",
    "from configs import device, data_dims\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data type:  float32\n"
     ]
    }
   ],
   "source": [
    "data_directory    = os.path.join(root_dir, \"data/\")\n",
    "dataset_name      = 'ppzee'\n",
    "\n",
    "#-- Set random seeds --#\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#-- Set data type --#\n",
    "from configs import float_type\n",
    "print('Using data type: ', float_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data total shapes:  (331699, 8) (331699, 8)\n",
      "z_train shape, x_train shape:  (291699, 8) (291699, 8)\n",
      "z_val   shape, x_val   shape:  (40000, 8) (40000, 8)\n"
     ]
    }
   ],
   "source": [
    "from func_utils import get_dataset, standardize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#-- Get training and validation dataset --#\n",
    "dataset = get_dataset(dataset_name, data_dir=data_directory) \n",
    "z_data, x_data = dataset['z_data'], dataset['x_data']\n",
    "\n",
    "MET = False # Exclude Missing Transverse Energy (MET) from x-space data\n",
    "if MET == False:\n",
    "    x_data = x_data[:, :-4]\n",
    "print(\"Data total shapes: \",z_data.shape, x_data.shape)\n",
    "\n",
    "x_dim = int(x_data.shape[1])\n",
    "z_dim = int(z_data.shape[1])\n",
    "\n",
    "#-- Split into training and validation sets --#\n",
    "train_size = 291699\n",
    "val_size = 40000  # Validation set used to evaluate/tune models\n",
    "\n",
    "x_train = x_data[:train_size, :]\n",
    "x_val = x_data[train_size:train_size+val_size, :]\n",
    "\n",
    "z_train = z_data[:train_size, :]\n",
    "z_val = z_data[train_size:train_size+val_size, :]\n",
    "\n",
    "#-- Convert data to proper type --#\n",
    "x_train, x_val, z_train, z_val = list(map(lambda x: x.astype(float_type), [x_train, x_val, z_train, z_val]))\n",
    "\n",
    "#-- Obtain mean and std information --#\n",
    "# This is needed to standardize/unstandardize data\n",
    "x_train_mean, x_train_std = np.mean(x_train, axis=0), np.std(x_train, axis=0) \n",
    "z_train_mean, z_train_std = np.mean(z_train, axis=0), np.std(z_train, axis=0)\n",
    "\n",
    "#-- Set evaluation parameters --#\n",
    "eval_batch_size = 20000  # Always use high batch size on validation set to accurately assess performance\n",
    "eval_loaders = DataLoader(dataset=x_val, batch_size=eval_batch_size, shuffle=True), \\\n",
    "               DataLoader(dataset=z_val, batch_size=eval_batch_size, shuffle=True)\n",
    "\n",
    "print(\"z_train shape, x_train shape: \", z_train.shape, x_train.shape)\n",
    "print(\"z_val   shape, x_val   shape: \", z_val.shape, x_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target invariant masses (for both training and validation data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invariant mass relation: $m^2 = E^2 - |\\vec{p}|^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X space\n",
      "particle 0 mass^2 = 2.01129e-15 +- 3.62862e-12\n",
      "particle 1 mass^2 = -1.17544e-14 +- 3.50494e-12\n",
      "Z space\n",
      "particle 0 mass^2 = -1.34586e-09 +- 6.17582e-07\n",
      "particle 1 mass^2 = -1.48398e-10 +- 5.71702e-07\n"
     ]
    }
   ],
   "source": [
    "#-- Look at m2 values empirically --#\n",
    "print('X space')\n",
    "tmp = x_data\n",
    "for i in range(int(tmp.shape[1] / 4)):\n",
    "    p = tmp[:, 4*i : 4*i+3]  # 3-momentum, (px, py, pz)\n",
    "    E = tmp[:, 4*i+3]        # Energy\n",
    "    m2 = (E**2 - (p ** 2).sum(axis=-1))\n",
    "    print('particle %d mass^2 = %g +- %g' %(i, m2.mean(), m2.std()))\n",
    "\n",
    "print('Z space')\n",
    "tmp = z_data\n",
    "for i in range(int(tmp.shape[1] / 4)):\n",
    "    p = tmp[:, 4*i : 4*i+3]  # 3-momentum, (px, py, pz)\n",
    "    E = tmp[:, 4*i+3]        # Energy\n",
    "    m2 = (E**2 - (p ** 2).sum(axis=-1))\n",
    "    print('particle %d mass^2 = %g +- %g' %(i, m2.mean(), m2.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the fact that these values are slightly negative is a purely numerical effect. Thus we instead define them to the value they should have, namely 0. (massless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Define target invariant masses --#\n",
    "x_inv_masses = np.zeros(2)\n",
    "z_inv_masses = np.zeros(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Specific Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from ppzee_utils import train_and_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Meta Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_noise = True  # Whether to use conditional Gaussian (instead of standard normal) for noise in enc/dec\n",
    "if cond_noise:\n",
    "    from models import CondNoiseAutoencoder\n",
    "    Autoencoder = CondNoiseAutoencoder  # Define alias \n",
    "else:\n",
    "    from models import Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Latent loss function: \n",
    "Finite sample approximation of Sliced Wasserstein Distance (SWD) between $p(z)$ and $p_E(z) = \\int_x p(x) p_E(z|x)$\n",
    "- $L_{latent}(Z, \\tilde{Z}) = \\frac{1}{L * M} \\sum_{l=1}^{L} \\sum_{m=1}^{M} c((\\theta_l \\cdot z_m)_{sorted}, (\\theta_l \\cdot \\tilde{z}_m)_{sorted})$ \n",
    "\n",
    "where $c(\\cdot, \\cdot) = |\\cdot - \\cdot|^2$\n",
    "\n",
    "###### Data loss function: \n",
    "- $L_{data}(X, \\tilde{X}) = \\frac{1}{M} \\sum_{m=1}^M c(x_m,  \\tilde{x}_m)$\n",
    "\n",
    "where $c(\\cdot, \\cdot) = |\\cdot - \\cdot|^2$\n",
    "\n",
    "###### Additional loss functions: \n",
    "Encoder and decoder anchor losses\n",
    "- $L_{A}(X, \\tilde{Z}) = \\frac{1}{M} \\sum_{m=1}^M c_A(x_m, \\tilde{z}_m)$\n",
    "- $L_{A}(Z, \\tilde{X}') = \\frac{1}{M} \\sum_{m=1}^M c_A(z_m, \\tilde{x}'_m)$\n",
    "\n",
    "see the paper for additional details about $c_A$.\n",
    "\n",
    "###### Full loss function:\n",
    "- $L_{tot} = \\beta L_{data}(X, \\tilde{X}) + \\lambda L_{latent}(Z, \\tilde{Z}) + \\nu_e L_{A}(X, \\tilde{Z}) + \\nu_d L_{A}(Z, \\tilde{X}')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Core Hyperparameters\n",
    "The hyperparameter definitions are as follows:\n",
    "- num_hidden_layers:    The number of hidden layers in both the encoder and decoder networks\n",
    "- dim_per_hidden_layer: The dimensions per hidden layer in both the encoder and decoder networks\n",
    "- lr: The learning rate of the networks\n",
    "- lamb: The $\\lambda$ coefficient in front of the latent loss term\n",
    "- num_slices: Number of random projections used for computing SWD\n",
    "- epochs: The number of epochs used during training\n",
    "\n",
    "Hyperparameters for other losses that were tried, but use during main training is currently discouraged:\n",
    "- tau: Coefficient in front of the alternate data-space loss (\"alt_x_loss\"), which is the SWD between $p(x)$ and $p_D(x):=\\int_z p(z) p_D(x|z)$\n",
    "- rho: Coefficient in front of an additional decoder constraint loss (based on soft-penalty approach to learning hard thresholds/ttbar_constraints)\n",
    "\n",
    "###### Joint Training Hyperparameters\n",
    "\n",
    "- beta: Coefficient in front of data loss, $L_{data}$     \n",
    "- nu_e: Coefficient in front of the encoder \"anchor loss\" \n",
    "- nu_d: Coefficient in front of the decoder \"anchor loss\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_hidden_layers': 1,\n",
    "    'dim_per_hidden_layer': 128,\n",
    "    'lr': 0.001,\n",
    "    'beta': 1.,  # weight of the data reconstruction loss\n",
    "    'lamb': 1.,  # weight of the latent space matching loss\n",
    "    'tau': 0,  \n",
    "    'rho': 0,  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "num_hidden_layers, dim_per_hidden_layer = config['num_hidden_layers'], config['dim_per_hidden_layer']\n",
    "hidden_layer_dims = num_hidden_layers * [dim_per_hidden_layer]\n",
    "\n",
    "activation = torch.nn.ReLU\n",
    "sigma_fun = 'softplus'  # Default is 'exp'\n",
    "model = Autoencoder(x_dim=x_dim, z_dim=z_dim, hidden_layer_dims=hidden_layer_dims, raw_io=True,\n",
    "                    x_stats=np.stack([x_train_mean, x_train_std]), z_stats=np.stack([z_train_mean, z_train_std]),\n",
    "                    x_inv_masses=x_inv_masses, z_inv_masses=z_inv_masses,\n",
    "                    stoch_enc=True, stoch_dec=True, activation=activation, sigma_fun=sigma_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CondNoiseAutoencoder(\n",
       "  (encoder): CondNoiseMLP(\n",
       "    (sigma_fun): Softplus(beta=1, threshold=20)\n",
       "    (output_nn): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "    (cond_noise_nn): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): CondNoiseMLP(\n",
       "    (sigma_fun): Softplus(beta=1, threshold=20)\n",
       "    (output_nn): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "    (cond_noise_nn): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 20000\n",
    "train_loaders = DataLoader(dataset=x_train, batch_size=train_batch_size, shuffle=True), \\\n",
    "                DataLoader(dataset=z_train, batch_size=train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through different hyperparameters and train/eval a model for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with initial anchor loss coef nu = 0\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:3736.88, x_loss:2947.43, z_loss:789.456, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2336.41, x_loss:2917.46, z_loss:704.736, alt_x_loss:1631.68, anchor_loss:1.99303\n",
      "epoch:\t100\n",
      "train -- loss:15.4132, x_loss:2.53477, z_loss:12.8784, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:10.0811, x_loss:2.21209, z_loss:2.76299, alt_x_loss:7.31814, anchor_loss:2.34349\n",
      "epoch:\t200\n",
      "train -- loss:4.5008, x_loss:0.853854, z_loss:3.64694, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:6.11704, x_loss:1.21233, z_loss:2.2783, alt_x_loss:3.83874, anchor_loss:2.37631\n",
      "epoch:\t300\n",
      "train -- loss:8.26902, x_loss:1.02083, z_loss:7.24818, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.60986, x_loss:1.67359, z_loss:1.97577, alt_x_loss:2.63409, anchor_loss:2.38834\n",
      "epoch:\t399\n",
      "train -- loss:3.27421, x_loss:0.546794, z_loss:2.72742, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.61724, x_loss:0.614185, z_loss:2.49106, alt_x_loss:3.12619, anchor_loss:2.3784\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:7.09164, x_loss:0.968188, z_loss:6.12345, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.5927, x_loss:1.09437, z_loss:2.17563, alt_x_loss:2.41708, anchor_loss:2.3747\n",
      "epoch:\t100\n",
      "train -- loss:7.95734, x_loss:1.10869, z_loss:6.84864, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.2183, x_loss:0.91784, z_loss:1.68988, alt_x_loss:2.52842, anchor_loss:2.37173\n",
      "epoch:\t200\n",
      "train -- loss:2.41016, x_loss:0.368829, z_loss:2.04133, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.89886, x_loss:0.465437, z_loss:1.66662, alt_x_loss:2.23223, anchor_loss:2.37391\n",
      "epoch:\t300\n",
      "train -- loss:4.25636, x_loss:0.574402, z_loss:3.68196, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.03255, x_loss:0.542255, z_loss:1.71004, alt_x_loss:2.32251, anchor_loss:2.37588\n",
      "epoch:\t400\n",
      "train -- loss:4.64792, x_loss:0.940759, z_loss:3.70716, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.27042, x_loss:0.417233, z_loss:2.30581, alt_x_loss:2.96461, anchor_loss:2.37902\n",
      "epoch:\t500\n",
      "train -- loss:15.4117, x_loss:0.66309, z_loss:14.7486, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.47878, x_loss:0.780076, z_loss:2.1515, alt_x_loss:2.32727, anchor_loss:2.37966\n",
      "epoch:\t600\n",
      "train -- loss:4.03205, x_loss:0.390127, z_loss:3.64192, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.40629, x_loss:0.738835, z_loss:2.51455, alt_x_loss:2.89173, anchor_loss:2.38109\n",
      "epoch:\t700\n",
      "train -- loss:3.34145, x_loss:0.211803, z_loss:3.12965, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.7383, x_loss:0.389249, z_loss:1.65244, alt_x_loss:2.08586, anchor_loss:2.37921\n",
      "epoch:\t799\n",
      "train -- loss:10.9897, x_loss:0.674012, z_loss:10.3157, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.75116, x_loss:0.238333, z_loss:2.17008, alt_x_loss:2.58109, anchor_loss:2.38392\n",
      "Saved model weights to ./swae-nu=0.pkl\n",
      "\n",
      "\n",
      "Training with initial anchor loss coef nu = 10\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 10, 'nu_d': 10, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:3744.42, x_loss:2937.73, z_loss:786.041, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.06437\n",
      "eval -- loss:2358.08, x_loss:2924.28, z_loss:710.451, alt_x_loss:1647.63, anchor_loss:1.98083\n",
      "epoch:\t100\n",
      "train -- loss:36.5668, x_loss:3.35815, z_loss:14.0056, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.92031\n",
      "eval -- loss:19.2177, x_loss:2.83034, z_loss:4.27474, alt_x_loss:14.943, anchor_loss:1.97463\n",
      "epoch:\t200\n",
      "train -- loss:25.5642, x_loss:1.85921, z_loss:5.72761, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.79774\n",
      "eval -- loss:24.7229, x_loss:1.31239, z_loss:3.85319, alt_x_loss:20.8697, anchor_loss:1.88637\n",
      "epoch:\t300\n",
      "train -- loss:25.4746, x_loss:1.22242, z_loss:8.56641, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.56857\n",
      "eval -- loss:55.4967, x_loss:1.65129, z_loss:3.88262, alt_x_loss:51.6141, anchor_loss:1.77224\n",
      "epoch:\t399\n",
      "train -- loss:21.5471, x_loss:1.70173, z_loss:6.21575, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.36296\n",
      "eval -- loss:125.669, x_loss:1.53871, z_loss:4.19277, alt_x_loss:121.476, anchor_loss:1.6824\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:11.1632, x_loss:1.64571, z_loss:9.5175, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:111.443, x_loss:2.25123, z_loss:3.68042, alt_x_loss:107.762, anchor_loss:1.70108\n",
      "epoch:\t100\n",
      "train -- loss:9.59084, x_loss:1.15136, z_loss:8.43948, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:17.2079, x_loss:1.24951, z_loss:2.05338, alt_x_loss:15.1546, anchor_loss:1.97168\n",
      "epoch:\t200\n",
      "train -- loss:2.84371, x_loss:0.736483, z_loss:2.10722, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:10.0302, x_loss:0.829143, z_loss:1.8429, alt_x_loss:8.1873, anchor_loss:2.06956\n",
      "epoch:\t300\n",
      "train -- loss:4.9004, x_loss:0.787214, z_loss:4.11318, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:8.28902, x_loss:0.904835, z_loss:2.04496, alt_x_loss:6.24406, anchor_loss:2.12905\n",
      "epoch:\t400\n",
      "train -- loss:4.48068, x_loss:0.90535, z_loss:3.57533, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:7.39211, x_loss:0.605374, z_loss:2.42155, alt_x_loss:4.97056, anchor_loss:2.17086\n",
      "epoch:\t500\n",
      "train -- loss:17.0152, x_loss:0.349925, z_loss:16.6653, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.9677, x_loss:0.513826, z_loss:2.22415, alt_x_loss:3.74354, anchor_loss:2.20283\n",
      "epoch:\t600\n",
      "train -- loss:3.87969, x_loss:0.622393, z_loss:3.2573, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:6.49861, x_loss:0.626371, z_loss:2.32069, alt_x_loss:4.17792, anchor_loss:2.22852\n",
      "epoch:\t700\n",
      "train -- loss:3.45036, x_loss:0.355582, z_loss:3.09478, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.10696, x_loss:0.489507, z_loss:1.82192, alt_x_loss:3.28504, anchor_loss:2.24494\n",
      "epoch:\t799\n",
      "train -- loss:10.3644, x_loss:0.512304, z_loss:9.85208, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:5.68143, x_loss:0.453688, z_loss:2.14578, alt_x_loss:3.53565, anchor_loss:2.26132\n",
      "Saved model weights to ./swae-nu=10.pkl\n",
      "\n",
      "\n",
      "Training with initial anchor loss coef nu = 20\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 20, 'nu_d': 20, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:3765.95, x_loss:2938.77, z_loss:786.295, alt_x_loss:0, x_constraint_loss:0, anchor_loss:2.04453\n",
      "eval -- loss:2367.21, x_loss:2925.36, z_loss:710.878, alt_x_loss:1656.33, anchor_loss:1.9648\n",
      "epoch:\t100\n",
      "train -- loss:51.6671, x_loss:4.815, z_loss:15.8306, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.55107\n",
      "eval -- loss:66.8723, x_loss:4.43521, z_loss:7.56717, alt_x_loss:59.3052, anchor_loss:1.6587\n",
      "epoch:\t200\n",
      "train -- loss:31.9258, x_loss:2.30251, z_loss:8.66506, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.04791\n",
      "eval -- loss:260.474, x_loss:2.30292, z_loss:8.35933, alt_x_loss:252.115, anchor_loss:1.33288\n",
      "epoch:\t300\n",
      "train -- loss:24.829, x_loss:2.79662, z_loss:12.5989, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.47167\n",
      "eval -- loss:402.174, x_loss:2.90579, z_loss:8.67446, alt_x_loss:393.5, anchor_loss:0.778177\n",
      "epoch:\t399\n",
      "train -- loss:12.7396, x_loss:2.8616, z_loss:6.69745, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.159027\n",
      "eval -- loss:308.515, x_loss:3.119, z_loss:4.84452, alt_x_loss:303.67, anchor_loss:0.282794\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:15.9059, x_loss:2.22601, z_loss:13.6799, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval -- loss:295.88, x_loss:2.40384, z_loss:4.85215, alt_x_loss:291.028, anchor_loss:0.288393\n",
      "epoch:\t100\n",
      "train -- loss:8.20357, x_loss:2.22069, z_loss:5.98289, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:187.255, x_loss:2.42391, z_loss:3.67476, alt_x_loss:183.58, anchor_loss:0.316254\n",
      "epoch:\t200\n",
      "train -- loss:4.35145, x_loss:1.32711, z_loss:3.02434, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:111.025, x_loss:1.26921, z_loss:2.82149, alt_x_loss:108.203, anchor_loss:0.301285\n",
      "epoch:\t300\n",
      "train -- loss:5.36957, x_loss:1.12163, z_loss:4.24794, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:70.08, x_loss:1.15147, z_loss:3.13107, alt_x_loss:66.9489, anchor_loss:0.281126\n",
      "epoch:\t400\n",
      "train -- loss:7.82801, x_loss:0.924961, z_loss:6.90305, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:48.3987, x_loss:0.642002, z_loss:3.45811, alt_x_loss:44.9406, anchor_loss:0.26366\n",
      "epoch:\t500\n",
      "train -- loss:17.583, x_loss:0.818289, z_loss:16.7647, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:34.7293, x_loss:0.833462, z_loss:2.46724, alt_x_loss:32.2621, anchor_loss:0.236885\n",
      "epoch:\t600\n",
      "train -- loss:5.98261, x_loss:1.85169, z_loss:4.13092, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:24.8367, x_loss:2.19802, z_loss:2.55122, alt_x_loss:22.2855, anchor_loss:0.205164\n",
      "epoch:\t700\n",
      "train -- loss:3.95581, x_loss:0.648488, z_loss:3.30732, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:15.6724, x_loss:0.584349, z_loss:2.12122, alt_x_loss:13.5511, anchor_loss:0.173793\n",
      "epoch:\t799\n",
      "train -- loss:8.41476, x_loss:0.666602, z_loss:7.74816, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:14.7286, x_loss:0.491461, z_loss:3.26426, alt_x_loss:11.4644, anchor_loss:0.136903\n",
      "Saved model weights to ./swae-nu=20.pkl\n",
      "\n",
      "\n",
      "Training with initial anchor loss coef nu = 50\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 50, 'nu_d': 50, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:3830.17, x_loss:2943.64, z_loss:786.829, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.99395\n",
      "eval -- loss:2390.63, x_loss:2930.31, z_loss:711.992, alt_x_loss:1678.64, anchor_loss:1.9234\n",
      "epoch:\t100\n",
      "train -- loss:41.4457, x_loss:11.9029, z_loss:20.9698, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.171459\n",
      "eval -- loss:97.4924, x_loss:10.2757, z_loss:6.71555, alt_x_loss:90.7769, anchor_loss:0.327617\n",
      "epoch:\t200\n",
      "train -- loss:6.92196, x_loss:2.13721, z_loss:3.8017, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.019661\n",
      "eval -- loss:12.134, x_loss:2.29333, z_loss:1.71357, alt_x_loss:10.4205, anchor_loss:0.0373688\n",
      "epoch:\t300\n",
      "train -- loss:9.43353, x_loss:2.29432, z_loss:6.66549, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00947432\n",
      "eval -- loss:5.3053, x_loss:1.40895, z_loss:1.8481, alt_x_loss:3.45721, anchor_loss:0.0179548\n",
      "epoch:\t399\n",
      "train -- loss:3.49792, x_loss:0.741095, z_loss:2.4479, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00617849\n",
      "eval -- loss:4.17967, x_loss:0.785676, z_loss:1.48228, alt_x_loss:2.69739, anchor_loss:0.0121825\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:10.5641, x_loss:1.14898, z_loss:9.41511, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.5643, x_loss:0.942965, z_loss:1.23934, alt_x_loss:2.32496, anchor_loss:0.0126587\n",
      "epoch:\t100\n",
      "train -- loss:8.38131, x_loss:1.923, z_loss:6.4583, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.25219, x_loss:1.04912, z_loss:1.17782, alt_x_loss:2.07436, anchor_loss:0.0154588\n",
      "epoch:\t200\n",
      "train -- loss:3.20345, x_loss:0.521352, z_loss:2.6821, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.55691, x_loss:0.980435, z_loss:1.54184, alt_x_loss:2.01507, anchor_loss:0.0174515\n",
      "epoch:\t300\n",
      "train -- loss:3.98575, x_loss:0.622083, z_loss:3.36367, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.2736, x_loss:0.538984, z_loss:1.36625, alt_x_loss:1.90734, anchor_loss:0.0179142\n",
      "epoch:\t400\n",
      "train -- loss:8.19744, x_loss:0.735627, z_loss:7.46182, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.1526, x_loss:0.737309, z_loss:1.74375, alt_x_loss:2.40884, anchor_loss:0.0181433\n",
      "epoch:\t500\n",
      "train -- loss:16.821, x_loss:0.55331, z_loss:16.2676, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2.33375, x_loss:0.463243, z_loss:1.00493, alt_x_loss:1.32882, anchor_loss:0.018025\n",
      "epoch:\t600\n",
      "train -- loss:4.03997, x_loss:0.540177, z_loss:3.49979, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:3.17796, x_loss:0.673573, z_loss:1.54854, alt_x_loss:1.62941, anchor_loss:0.0176493\n",
      "epoch:\t700\n",
      "train -- loss:6.75477, x_loss:0.841268, z_loss:5.9135, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:2.78421, x_loss:1.18159, z_loss:0.962665, alt_x_loss:1.82154, anchor_loss:0.0175322\n",
      "epoch:\t799\n",
      "train -- loss:7.39643, x_loss:0.407033, z_loss:6.9894, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:4.97434, x_loss:0.484551, z_loss:2.2846, alt_x_loss:2.68974, anchor_loss:0.0172018\n",
      "Saved model weights to ./swae-nu=50.pkl\n",
      "\n",
      "\n",
      "Training with initial anchor loss coef nu = 100\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 100, 'nu_d': 100, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:3933.32, x_loss:2951.41, z_loss:788.614, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.93296\n",
      "eval -- loss:2417.37, x_loss:2938.22, z_loss:714.704, alt_x_loss:1702.67, anchor_loss:1.87269\n",
      "epoch:\t100\n",
      "train -- loss:26.4218, x_loss:9.70012, z_loss:14.6891, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.0203253\n",
      "eval -- loss:119.688, x_loss:10.0114, z_loss:5.55567, alt_x_loss:114.132, anchor_loss:0.0361378\n",
      "epoch:\t200\n",
      "train -- loss:14.8385, x_loss:8.76548, z_loss:5.44727, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00625729\n",
      "eval -- loss:117.016, x_loss:8.58124, z_loss:5.00149, alt_x_loss:112.014, anchor_loss:0.00912073\n",
      "epoch:\t300\n",
      "train -- loss:13.0359, x_loss:4.47516, z_loss:8.22564, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00335096\n",
      "eval -- loss:102.501, x_loss:4.32382, z_loss:4.20561, alt_x_loss:98.2958, anchor_loss:0.00430196\n",
      "epoch:\t399\n",
      "train -- loss:5.63677, x_loss:1.2561, z_loss:4.22224, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00158434\n",
      "eval -- loss:93.2577, x_loss:1.22597, z_loss:4.18755, alt_x_loss:89.0701, anchor_loss:0.00244002\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:9.45007, x_loss:1.11648, z_loss:8.33358, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:91.8844, x_loss:1.12383, z_loss:4.26425, alt_x_loss:87.6202, anchor_loss:0.00262942\n",
      "epoch:\t100\n",
      "train -- loss:8.06152, x_loss:1.3241, z_loss:6.73742, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:72.7306, x_loss:1.00805, z_loss:3.50563, alt_x_loss:69.2249, anchor_loss:0.0341829\n",
      "epoch:\t200\n",
      "train -- loss:4.95347, x_loss:1.54802, z_loss:3.40545, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:61.6473, x_loss:1.0143, z_loss:2.60742, alt_x_loss:59.0398, anchor_loss:0.0688218\n",
      "epoch:\t300\n",
      "train -- loss:4.83748, x_loss:0.865462, z_loss:3.97202, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:59.831, x_loss:1.10546, z_loss:2.96682, alt_x_loss:56.8641, anchor_loss:0.110083\n",
      "epoch:\t400\n",
      "train -- loss:8.49134, x_loss:0.497493, z_loss:7.99385, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:46.2013, x_loss:0.661178, z_loss:2.80353, alt_x_loss:43.3978, anchor_loss:0.152122\n",
      "epoch:\t500\n",
      "train -- loss:18.5793, x_loss:0.736735, z_loss:17.8426, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:38.5657, x_loss:0.978037, z_loss:2.24654, alt_x_loss:36.3192, anchor_loss:0.199343\n",
      "epoch:\t600\n",
      "train -- loss:4.47955, x_loss:0.478818, z_loss:4.00073, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:32.6293, x_loss:0.520401, z_loss:3.04145, alt_x_loss:29.5879, anchor_loss:0.252411\n",
      "epoch:\t700\n",
      "train -- loss:7.48842, x_loss:1.64056, z_loss:5.84786, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval -- loss:26.0569, x_loss:0.530531, z_loss:1.74214, alt_x_loss:24.3148, anchor_loss:0.299962\n",
      "epoch:\t799\n",
      "train -- loss:8.73799, x_loss:0.522676, z_loss:8.21531, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:24.7256, x_loss:0.970133, z_loss:3.42714, alt_x_loss:21.2985, anchor_loss:0.341218\n",
      "Saved model weights to ./swae-nu=100.pkl\n",
      "\n",
      "\n",
      "Training with initial anchor loss coef nu = 200\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 200, 'nu_d': 200, 'epochs': 400}\n",
      "epoch:\t0\n",
      "train -- loss:4123.88, x_loss:2964.67, z_loss:792.926, alt_x_loss:0, x_constraint_loss:0, anchor_loss:1.83143\n",
      "eval -- loss:2441.76, x_loss:2951.69, z_loss:720.754, alt_x_loss:1721.01, anchor_loss:1.7927\n",
      "epoch:\t100\n",
      "train -- loss:26.1324, x_loss:9.82825, z_loss:14.9408, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.0068167\n",
      "eval -- loss:125.682, x_loss:9.31919, z_loss:5.41894, alt_x_loss:120.263, anchor_loss:0.00995276\n",
      "epoch:\t200\n",
      "train -- loss:14.0012, x_loss:8.07333, z_loss:5.23464, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00346619\n",
      "eval -- loss:137, x_loss:8.0088, z_loss:3.955, alt_x_loss:133.045, anchor_loss:0.00396445\n",
      "epoch:\t300\n",
      "train -- loss:17.6077, x_loss:7.8453, z_loss:9.15788, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00302253\n",
      "eval -- loss:121.593, x_loss:8.1275, z_loss:2.67968, alt_x_loss:118.913, anchor_loss:0.00314467\n",
      "epoch:\t399\n",
      "train -- loss:5.90476, x_loss:1.6797, z_loss:4.02079, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0.00102135\n",
      "eval -- loss:131.494, x_loss:1.75894, z_loss:3.26334, alt_x_loss:128.231, anchor_loss:0.00138321\n",
      "{'num_hidden_layers': 1, 'dim_per_hidden_layer': 128, 'lr': 0.001, 'beta': 1.0, 'lamb': 1.0, 'tau': 0, 'rho': 0, 'nu_e': 0, 'nu_d': 0, 'epochs': 800}\n",
      "epoch:\t0\n",
      "train -- loss:10.0519, x_loss:1.72667, z_loss:8.3252, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:129.642, x_loss:1.82738, z_loss:2.85127, alt_x_loss:126.791, anchor_loss:0.00157144\n",
      "epoch:\t100\n",
      "train -- loss:9.26708, x_loss:1.94053, z_loss:7.32655, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:109.547, x_loss:1.46608, z_loss:2.17541, alt_x_loss:107.372, anchor_loss:0.00719158\n",
      "epoch:\t200\n",
      "train -- loss:4.10767, x_loss:0.651159, z_loss:3.45651, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:102.282, x_loss:0.835473, z_loss:2.17931, alt_x_loss:100.103, anchor_loss:0.0188212\n",
      "epoch:\t300\n",
      "train -- loss:5.39642, x_loss:0.918122, z_loss:4.4783, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:88.7053, x_loss:0.780244, z_loss:1.93106, alt_x_loss:86.7742, anchor_loss:0.0251136\n",
      "epoch:\t400\n",
      "train -- loss:7.6418, x_loss:0.543826, z_loss:7.09797, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:69.4284, x_loss:0.629205, z_loss:2.27415, alt_x_loss:67.1543, anchor_loss:0.0274474\n",
      "epoch:\t500\n",
      "train -- loss:17.2867, x_loss:0.731042, z_loss:16.5557, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:52.3338, x_loss:0.573117, z_loss:1.17836, alt_x_loss:51.1554, anchor_loss:0.0286957\n",
      "epoch:\t600\n",
      "train -- loss:4.76443, x_loss:1.13451, z_loss:3.62991, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:39.3597, x_loss:0.536786, z_loss:1.82587, alt_x_loss:37.5338, anchor_loss:0.0293185\n",
      "epoch:\t700\n",
      "train -- loss:5.97593, x_loss:0.933271, z_loss:5.04265, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:25.4339, x_loss:0.780346, z_loss:2.50411, alt_x_loss:22.9298, anchor_loss:0.0267329\n",
      "epoch:\t799\n",
      "train -- loss:7.34632, x_loss:0.567736, z_loss:6.77859, alt_x_loss:0, x_constraint_loss:0, anchor_loss:0\n",
      "eval -- loss:19.5816, x_loss:0.331793, z_loss:2.21483, alt_x_loss:17.3667, anchor_loss:0.0255056\n",
      "Saved model weights to ./swae-nu=200.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "save_dir = '.'\n",
    "\n",
    "nus = [0, 10, 20, 50, 100, 200]\n",
    "for nu in nus:\n",
    "    print(f'Training with initial anchor loss coef nu = {nu}')\n",
    "\n",
    "    # Reset seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Create a new model and optimizer\n",
    "    model = Autoencoder(x_dim=x_dim, z_dim=z_dim, hidden_layer_dims=hidden_layer_dims, raw_io=True,\n",
    "                    x_stats=np.stack([x_train_mean, x_train_std]), z_stats=np.stack([z_train_mean, z_train_std]),\n",
    "                    x_inv_masses=x_inv_masses, z_inv_masses=z_inv_masses,\n",
    "                    stoch_enc=True, stoch_dec=True, activation=activation, sigma_fun=sigma_fun)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    \n",
    "    #  Stage-1 training with the anchor penalty\n",
    "    config['nu_e'] = config['nu_d'] = nu\n",
    "    config['epochs'] = 400  # originally 200; increased to 400 to ensure convergence\n",
    "    history = None\n",
    "    eval_losses, history = train_and_val(model, train_loaders, eval_loaders, config, optimizer, verbose=verbose, \n",
    "                                          prev_hist=history, log_freq=100, lr_decay=False)\n",
    "    # Stage-2 training without the anchor penalty\n",
    "    config['nu_e'] = config['nu_d'] = 0\n",
    "    config['epochs'] = 800  # originally 600; increased to 800 to ensure convergence\n",
    "#     history = None\n",
    "    eval_losses, history = train_and_val(model, train_loaders, eval_loaders, config, optimizer, verbose=verbose, \n",
    "                                          prev_hist=history, log_freq=100, lr_decay=False)\n",
    "    # Save history in JSON-lines format\n",
    "    ## convert pytorch float tensors into plain numpy float arrs in history\n",
    "    for key, val in history.items():\n",
    "        if isinstance(val, (list, np.ndarray)) :\n",
    "            if not isinstance(np.sum(val), (int, np.integer)):  # my crude test to see if this is an array of float type\n",
    "                history[key] = [float(n) for n in val]\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(history)\n",
    "    df.to_json(f'history-nu={nu}.jsonl', orient='records', lines=True)\n",
    "    \n",
    "\n",
    "    # Save trained model\n",
    "    save_path = os.path.join(save_dir, f'swae-nu={nu}.pkl')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print('Saved model weights to', save_path)\n",
    "\n",
    "    # Reset seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # Collect model results\n",
    "    model.to('cpu')\n",
    "    model.encoder.output_stats.to('cpu')\n",
    "    model.decoder.output_stats.to('cpu')\n",
    "\n",
    "    all_arrs = {'train': {}, 'val': {}}  # This will store all numpy arrays of interest\n",
    "    all_arrs['train']['x'] = x_train\n",
    "    all_arrs['train']['z'] = z_train\n",
    "    all_arrs['val']['x']   = x_val\n",
    "    all_arrs['val']['z']   = z_val\n",
    "\n",
    "    for data_key in 'train', 'val':\n",
    "        arrs = all_arrs[data_key]\n",
    "        arrs['z_decoded']       = model.decode(torch.from_numpy(arrs['z'])) # p_D(x) = \\int_z p(z) p_D(x|z)  \"x_pred_truth\"\n",
    "        arrs['x_encoded']       = model.encode(torch.from_numpy(arrs['x'])) # p_E(z) = \\int_x p(x) p_E(z|x)  \"z_pred\"\n",
    "        arrs['x_reconstructed'] = model.decode(arrs['x_encoded'])     # p_D(y) = \\int_x \\int_z p(x) p_E(z|x) p_D(y|z) \"x_pred\"\n",
    "\n",
    "        # Feed the same z input to the decoder multiple times and study the stochastic of the output\n",
    "        num_repeats = 100\n",
    "        num_diff_zs = 100\n",
    "        arrs['z_rep']         = np.array([np.repeat(arrs['z'][i:i+1], num_repeats, axis=0) for i in range(num_diff_zs)]) # \"z_fixed\"\n",
    "        z_rep_tensor          = torch.from_numpy(arrs['z_rep'])                                                          # tmp\n",
    "        arrs['z_decoded_rep'] = np.array([model.decode(z_rep_tensor[i]).detach().numpy() for i in range(num_diff_zs)])   # \"x_pred_truth_fixed\"\n",
    "        arrs['x_rep']         = np.array([np.repeat(arrs['x'][i:i+1], num_repeats, axis=0) for i in range(num_diff_zs)]) # \"x_fixed\"\n",
    "\n",
    "        # Convert all results to numpy arrays\n",
    "        for (field, arr) in arrs.items():\n",
    "            if isinstance(arr, torch.Tensor):\n",
    "                arrs[field] = arr.detach().numpy()\n",
    "    \n",
    "    from plot_utils import plotFunction\n",
    "    # Z-space\n",
    "    data_key = 'val'\n",
    "    arrs = all_arrs[data_key]\n",
    "    dataList = [arrs['z'], arrs['x_encoded']]\n",
    "    pltDim   = (2,4)\n",
    "    numBins  = 50\n",
    "    binsList = [np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins),\n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins)]\n",
    "    particleNameList = [r'$e^-$', r'$e^+$']\n",
    "\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList = binsList, particleNameList = particleNameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'Z_marginals-nu={nu}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # X-space\n",
    "    # Set plotting parameters\n",
    "    dataList = [arrs['x'], arrs['x_reconstructed'], arrs['z_decoded']]\n",
    "    pltDim   = (2,4)\n",
    "    numBins  = 50\n",
    "    binsList = [np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins),\n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-100.,100., numBins), \n",
    "                np.linspace(-400.,400., numBins), \n",
    "                np.linspace(0.,400., numBins)]\n",
    "    particleNameList = [r'$e^-$', r'$e^+$']\n",
    "\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList = binsList, particleNameList = particleNameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'X_marginals-nu={nu}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Derived quantity (Z-boson mass)\n",
    "    from func_utils import Zboson_mass\n",
    "    ## Z-space\n",
    "    dataList = [Zboson_mass(arrs['z']), Zboson_mass(arrs['x_encoded'])]\n",
    "    pltDim   = (1,1)\n",
    "    numBins  = 40\n",
    "    binsList = [np.linspace(70.,110., numBins)]\n",
    "    particleNameList = []\n",
    "    nameList = [r'$M_Z$', r'Counts']\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList=binsList, particleNameList=particleNameList, nameList=nameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'Z_derived-nu={nu}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    ## X-space\n",
    "    dataList = [Zboson_mass(arrs['x']), Zboson_mass(arrs['x_reconstructed']), Zboson_mass(arrs['z_decoded'])] \n",
    "    pltDim   = (1,1)\n",
    "    numBins  = 40\n",
    "    binsList = [np.linspace(70.,110., numBins)]\n",
    "    particleNameList = []\n",
    "    nameList = [r'$M_Z$', r'Counts']\n",
    "\n",
    "    # Create plot\n",
    "    fig = plotFunction(dataList = dataList, pltDim = pltDim, binsList=binsList, particleNameList=particleNameList, nameList=nameList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'X_derived-nu={nu}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    # Transport plots\n",
    "    from plot_utils import fullTransportPlot \n",
    "    nzList    = [20,20,20,20,20,20,20,20]\n",
    "    nxList    = [20,20,20,20,20,20,20,20]\n",
    "    x_display_lims = [(-100, 100), (-100, 100), (-400, 400), (0, 400)]\n",
    "    limzList = x_display_lims * 2\n",
    "    limxList = x_display_lims * 2\n",
    "    pltDim    = (2,4)\n",
    "    titleList = [r'$p_x$',r'$p_y$',r'$p_z$',r'$E$','','','','']\n",
    "    fig = fullTransportPlot(arrs['z'], arrs['z_decoded'][:, 0:8], nzList=nzList, nxList=nxList, limzList=limzList, limxList=limxList, pltDim=pltDim, titleList=titleList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'z-z_decoded-transport-nu={nu}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = fullTransportPlot(arrs['x_encoded'], arrs['x_reconstructed'][:, 0:8], nzList=nzList, nxList=nxList, limzList=limzList, limxList=limxList, pltDim=pltDim, titleList=titleList, show=False)\n",
    "    fig.savefig(os.path.join(save_dir, f'x_encoded-x_reconstructed-transport-nu={nu}.png'), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
